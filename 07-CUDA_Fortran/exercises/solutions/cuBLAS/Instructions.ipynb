{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced GPU Programming 2023\n",
    "\n",
    "* Date: 19 - 23 April 2023\n",
    "* Location: _online_\n",
    "* Institue: Jülich Supercomputing Centre"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cuBLAS\n",
    "\n",
    "\n",
    "#### Setup\n",
    "\n",
    "Either use the Terminal you opened for Task 1 or open a new Terminal (again, through `File` → `New` → `Terminal`).\n",
    "\n",
    "Make your way to `07-CUDA_Fortran/exercises/tasks/cuBLAS`.\n",
    "\n",
    "Call `source setup.sh` to load the modules of this task into your environment. (They are much different from Task 1 and more similar to our general module setup for this course.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description\n",
    "\n",
    "In this exercise, we use the BLAS3 routine DGEMM in cuBLAS to perform a matrix-matrix\n",
    "multiplication using double precision. GEMM is defined as\n",
    "\n",
    "$C=\\alpha A B + \\beta C$,\n",
    "\n",
    "where $A$, $B$, and $C$ are matrices and $\\alpha$ and $\\beta$ are scalars. \n",
    "\n",
    "In our case, we only want to multiply $A$ and $B$ so we set $\\beta=0$.\n",
    "\n",
    "The program (implemented in file `dgemm.cuf`) allocates space for two square matrices *A* and *B* and fills them with random numbers generated by cuRAND."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "\n",
    "Implement the call to `cublasDgemm` (marked with `TODO`). See the cuBLAS documentation for further information: http://docs.nvidia.com/cuda/cublas/.\n",
    "\n",
    "Compile the code by calling `make dgemm`. Remember to load the custom modules of this task by calling ``source setup.sh``.\n",
    "\n",
    "Run the code on the HPC system with ``make run`` or ``make run-Fortran``. Copy the ``make run`` command and change the argument to the program to run the multiplication for different matrix sizes. Try a few!\n",
    "\n",
    "Is the performance what you would have expected? Compare with the results from the previous exercise.\n",
    "\n",
    "Read the code and find the CUDA specific calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
